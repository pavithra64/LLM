{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavithra64/LLM/blob/main/linkedin_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKsEa407kDsZ"
      },
      "source": [
        "**Designing and developing a large language model (LLM) to generate human-like, professional LinkedIn posts across various themes—while ensuring complete independence from external APIs.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqCnISmCkU63"
      },
      "source": [
        "**Objective:** Build an LLM that can generate contextually rich, professional, and engaging LinkedIn posts.\n",
        "\n",
        "**Independence:** No reliance on external APIs (e.g., OpenAI, Anthropic).\n",
        "\n",
        "**Deployment Target:** On-premises or private cloud setup for control and privacy.\n",
        "\n",
        "**Capabilities:** The model should understand:\n",
        "\n",
        "Tone, style, and audience of LinkedIn posts.\n",
        "\n",
        "**Contextual themes:** career advice, product launches, achievements, events, hiring, etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdiJoKRxqgBA"
      },
      "source": [
        "**Steps**\n",
        "\n",
        "\n",
        "Environment Setup\n",
        "\n",
        "Select a Base LLM\n",
        "\n",
        "Collect and Prepare Dataset\n",
        "\n",
        "Preprocess Data\n",
        "\n",
        "Fine-tune LLM with LoRA\n",
        "\n",
        "Generate LinkedIn Posts Locally\n",
        "\n",
        "Deploy the Model Locally\n",
        "\n",
        "Build a Simple UI\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwgTI863qq_a"
      },
      "source": [
        "**Environment Setup**\n",
        "\n",
        "**Requirements**\n",
        "\n",
        "GPU (NVIDIA with ≥16GB VRAM recommended)\n",
        "\n",
        "Python ≥ 3.10\n",
        "\n",
        "Linux or WSL (Windows Subsystem for Linux)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9O0dlEjjweU",
        "outputId": "7e20efdf-232e-43e4-f7f0-31b2d0492530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install transformers datasets peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkA4SwSyv5HV",
        "outputId": "d36a361d-b203-487e-a888-9d50879eb108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=2.2->bitsandbytes) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_RRn4Jbq8Gd",
        "outputId": "f68de1c5-2041-49d7-dfa1-ed8945943ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        }
      ],
      "source": [
        "#Select Base LLM\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# model_name = \"mistralai/Mistral-7B-v0.1\" # This model is gated and requires authentication\n",
        "model_name = \"gpt2\" # Using an open-source model that does not require authentication\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_8bit=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9a28651"
      },
      "source": [
        "# Collect and Prepare Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "dabf1b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab3cf736-05e0-4777-9121-1265dde31913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated dataset:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'theme': 'career milestone',\n",
              "  'tone': 'humble',\n",
              "  'persona': 'Software Engineer',\n",
              "  'input': 'Started new job at Google',\n",
              "  'output': \"Thrilled to announce I've joined Google as a Software Engineer! Looking forward to this new chapter.\"},\n",
              " {'theme': 'product launch',\n",
              "  'tone': 'exciting',\n",
              "  'persona': 'Product Manager',\n",
              "  'input': 'Launching new feature',\n",
              "  'output': 'Excited to launch our new feature that will revolutionize the way we work!'},\n",
              " {'theme': 'achievement',\n",
              "  'tone': 'proud',\n",
              "  'persona': 'Data Scientist',\n",
              "  'input': 'Completed a challenging project',\n",
              "  'output': 'Successfully completed a challenging data science project, leveraging machine learning to gain valuable insights.'},\n",
              " {'theme': 'hiring',\n",
              "  'tone': 'enthusiastic',\n",
              "  'persona': 'Hiring Manager',\n",
              "  'input': 'We are hiring!',\n",
              "  'output': \"Our team is growing! We're looking for talented individuals to join us.\"},\n",
              " {'theme': 'event',\n",
              "  'tone': 'invitational',\n",
              "  'persona': 'Marketing Specialist',\n",
              "  'input': 'Join our webinar',\n",
              "  'output': \"Don't miss our upcoming webinar on the latest trends in marketing. Register now!\"},\n",
              " {'theme': 'career advice',\n",
              "  'tone': 'helpful',\n",
              "  'persona': 'Career Coach',\n",
              "  'input': 'Tips for interviewing',\n",
              "  'output': 'Here are my top tips for acing your next job interview.'},\n",
              " {'theme': 'industry news',\n",
              "  'tone': 'informative',\n",
              "  'persona': 'Industry Analyst',\n",
              "  'input': 'New report on tech trends',\n",
              "  'output': 'Read our latest report on the emerging trends in the tech industry.'},\n",
              " {'theme': 'company culture',\n",
              "  'tone': 'authentic',\n",
              "  'persona': 'HR Manager',\n",
              "  'input': 'Our values in action',\n",
              "  'output': 'Proud to see our company values reflected in the daily work of our team.'},\n",
              " {'theme': 'project update',\n",
              "  'tone': 'progress-focused',\n",
              "  'persona': 'Project Lead',\n",
              "  'input': 'Project X progress',\n",
              "  'output': 'Making great progress on Project X! Stay tuned for more updates.'},\n",
              " {'theme': 'networking',\n",
              "  'tone': 'open',\n",
              "  'persona': 'Business Developer',\n",
              "  'input': 'Connecting with professionals',\n",
              "  'output': 'Enjoyed connecting with so many inspiring professionals at [Event Name].'},\n",
              " {'theme': 'skill sharing',\n",
              "  'tone': 'educational',\n",
              "  'persona': 'Educator',\n",
              "  'input': 'Learn Python basics',\n",
              "  'output': 'Sharing a quick tutorial on Python basics for beginners.'},\n",
              " {'theme': 'thought leadership',\n",
              "  'tone': 'insightful',\n",
              "  'persona': 'CEO',\n",
              "  'input': 'Future of work',\n",
              "  'output': 'My thoughts on the future of work and how we can adapt.'},\n",
              " {'theme': 'customer success',\n",
              "  'tone': 'grateful',\n",
              "  'persona': 'Account Manager',\n",
              "  'input': 'Client success story',\n",
              "  'output': 'Celebrating a fantastic success story with our client [Client Name]!'}]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['theme', 'tone', 'persona', 'input', 'output'],\n",
              "    num_rows: 13\n",
              "})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "data = [\n",
        "        {\"theme\": \"career milestone\", \"tone\": \"humble\", \"persona\": \"Software Engineer\", \"input\": \"Started new job at Google\", \"output\": \"Thrilled to announce I've joined Google as a Software Engineer! Looking forward to this new chapter.\"},\n",
        "        {\"theme\": \"product launch\", \"tone\": \"exciting\", \"persona\": \"Product Manager\", \"input\": \"Launching new feature\", \"output\": \"Excited to launch our new feature that will revolutionize the way we work!\"},\n",
        "        {\"theme\": \"achievement\", \"tone\": \"proud\", \"persona\": \"Data Scientist\", \"input\": \"Completed a challenging project\", \"output\": \"Successfully completed a challenging data science project, leveraging machine learning to gain valuable insights.\"},\n",
        "        {\"theme\": \"hiring\", \"tone\": \"enthusiastic\", \"persona\": \"Hiring Manager\", \"input\": \"We are hiring!\", \"output\": \"Our team is growing! We're looking for talented individuals to join us.\"},\n",
        "        {\"theme\": \"event\", \"tone\": \"invitational\", \"persona\": \"Marketing Specialist\", \"input\": \"Join our webinar\", \"output\": \"Don't miss our upcoming webinar on the latest trends in marketing. Register now!\"},\n",
        "        {\"theme\": \"career advice\", \"tone\": \"helpful\", \"persona\": \"Career Coach\", \"input\": \"Tips for interviewing\", \"output\": \"Here are my top tips for acing your next job interview.\"},\n",
        "        {\"theme\": \"industry news\", \"tone\": \"informative\", \"persona\": \"Industry Analyst\", \"input\": \"New report on tech trends\", \"output\": \"Read our latest report on the emerging trends in the tech industry.\"},\n",
        "        {\"theme\": \"company culture\", \"tone\": \"authentic\", \"persona\": \"HR Manager\", \"input\": \"Our values in action\", \"output\": \"Proud to see our company values reflected in the daily work of our team.\"},\n",
        "        {\"theme\": \"project update\", \"tone\": \"progress-focused\", \"persona\": \"Project Lead\", \"input\": \"Project X progress\", \"output\": \"Making great progress on Project X! Stay tuned for more updates.\"},\n",
        "        {\"theme\": \"networking\", \"tone\": \"open\", \"persona\": \"Business Developer\", \"input\": \"Connecting with professionals\", \"output\": \"Enjoyed connecting with so many inspiring professionals at [Event Name].\"},\n",
        "        {\"theme\": \"skill sharing\", \"tone\": \"educational\", \"persona\": \"Educator\", \"input\": \"Learn Python basics\", \"output\": \"Sharing a quick tutorial on Python basics for beginners.\"},\n",
        "        {\"theme\": \"thought leadership\", \"tone\": \"insightful\", \"persona\": \"CEO\", \"input\": \"Future of work\", \"output\": \"My thoughts on the future of work and how we can adapt.\"},\n",
        "        {\"theme\": \"customer success\", \"tone\": \"grateful\", \"persona\": \"Account Manager\", \"input\": \"Client success story\", \"output\": \"Celebrating a fantastic success story with our client [Client Name]!\"}\n",
        "]\n",
        "\n",
        "print(\"Updated dataset:\")\n",
        "display(data)\n",
        "\n",
        "\n",
        "# Convert the list of dictionaries to a Dataset\n",
        "dataset = Dataset.from_list(data)\n",
        "\n",
        "\n",
        "print(\"Dataset loaded successfully:\")\n",
        "display(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "3sS5HltLx3vi"
      },
      "outputs": [],
      "source": [
        "# split the dataset into training and validation sets\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = dataset['train']\n",
        "validation_dataset = dataset['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "933fd002"
      },
      "source": [
        "## Preprocess Data\n",
        "\n",
        "Tokenize the dataset to prepare it for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_Wy_3B-6zykS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "85ef379e0e0d4b9f8ec25dc0662d4228",
            "97dfc0b239e7492c9e8c90153511b5eb",
            "04501cc2625f43c888af4e4ce40e769d",
            "0a89e9ccfcdf47109e08dc0ec242cd4a",
            "56674944ffdd440091d747fe4c356a2d",
            "5081fd0bddac4cc281942d21062b2cb0",
            "71e762fe9c4f482381477093caf123c6",
            "de9b74156137480782b5fcac99ed5b58",
            "67c5796d72aa4520851610dcfc8ec5a7",
            "0b0978bbf58647fc95c43eccab69c085",
            "562f683a35bc42178dda66fc7101cc10",
            "8381042393434988a02f842b792a88df",
            "7c979df6e92145c38b7a12882b525b9e",
            "723c1a03fb594acaae6686f9de62782d",
            "520e4c6e881b4509b1f14538d0635071",
            "eb2a586dfcee4a28a931d74960dc3b34",
            "819a6f1b76674e66a89806fd3b67ad42",
            "cb283b10f6ba42ad96be1fc942fa9f3b",
            "e93600f43af54090a2f21c8919bcf8c2",
            "c08de282526d448b8a9c3b84d7fffd73",
            "ab40ba5d09cd4f17990dcd63869f0b52",
            "6e74b04d55d5406da1b7054b4ba12c5b"
          ]
        },
        "outputId": "6e89f740-ff45-46b1-c346-3ae734852289"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85ef379e0e0d4b9f8ec25dc0662d4228"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8381042393434988a02f842b792a88df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized dataset:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['theme', 'tone', 'persona', 'input', 'output', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 11\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['theme', 'tone', 'persona', 'input', 'output', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 2\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def tokenize_function(examples):\n",
        "    # Combine the input features into a single text string for the model\n",
        "    text = [f\"Theme: {t}\\nTone: {to}\\nPersona: {p}\\nInput: {i}\\nOutput: {o}\" for t, to, p, i, o in zip(examples[\"theme\"], examples[\"tone\"], examples[\"persona\"], examples[\"input\"], examples[\"output\"])]\n",
        "    return tokenizer(text, padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Set the padding token for the tokenizer\n",
        "tokenizer.pad_token=tokenizer.eos_token\n",
        "\n",
        "# Apply the tokenization function to the dataset\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# You can inspect the tokenized dataset\n",
        "print(\"Tokenized dataset:\")\n",
        "display(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiE62weD0joU"
      },
      "source": [
        "**Fine-tune LLM with PEFT + LoRA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TfFROPBZ0mde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcf4ab1-0566-4d5e-8ebd-93079c752333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.2364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "\n",
        "    target_modules=[\"c_attn\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Print the number of trainable parameters\n",
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QOakrJr1g69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "44430ba4-0f03-40ba-9e8e-d9c907a03733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/6 21:29 < 1:04:27, 0.00 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Training Setup\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./linkedin-llm\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    save_total_limit=1,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],  # Specify the training split\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzyOFnj-1t3V"
      },
      "outputs": [],
      "source": [
        "peft_model.save_pretrained(\"./linkedin-llm\")\n",
        "tokenizer.save_pretrained(\"./linkedin-llm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate LinkedIn Posts Locally\n",
        "from transformers import pipeline\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "# Load the PEFT configuration\n",
        "config = PeftConfig.from_pretrained(\"./linkedin-llm\")"
      ],
      "metadata": {
        "id": "dcxmPzrwTKw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoSfVdkR49uG"
      },
      "outputs": [],
      "source": [
        "#Generate LinkedIn Posts Locally\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "# Load the PEFT configuration\n",
        "config = PeftConfig.from_pretrained(\"./linkedin-llm\")\n",
        "\n",
        "# Define the quantization configuration\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    bnb_8bit_compute_dtype=torch.float16, # Add this line\n",
        "    bnb_8bit_quant_type=\"nf4\", # Add this line\n",
        "    bnb_8bit_use_double_quant=True, # Add this line\n",
        ")\n",
        "\n",
        "\n",
        "# Load the base model\n",
        "base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, quantization_config=bnb_config, device_map=\"auto\")\n",
        "\n",
        "# Load the PEFT model\n",
        "peft_model = PeftModel.from_pretrained(base_model, \"./linkedin-llm\")\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./linkedin-llm\")\n",
        "\n",
        "# Create the text generation pipeline\n",
        "pipe = pipeline(\"text-generation\", model=peft_model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxtZP_OV7hZ3"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"### INSTRUCTION:\n",
        "Write a confident LinkedIn post on the theme \"career switch\".\n",
        "Role: Data Analyst\n",
        "Event: Transitioned to Data Scientist at Microsoft\n",
        "\n",
        "### RESPONSE:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = pipe(\n",
        "    prompt,\n",
        "    max_new_tokens=200,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=50,\n",
        "    do_sample=True,\n",
        "    num_return_sequences=1\n",
        ")[0]['generated_text']"
      ],
      "metadata": {
        "id": "bYsKWYGnUx4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8U_nywoAyug"
      },
      "outputs": [],
      "source": [
        "#Deploy Model Locally (Inference Server)\n",
        "\n",
        "!pip install text-generation\n",
        "\n",
        "text-generation-launcher --model-id ./linkedin-llm --quantize gptq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDV2N144BIrO"
      },
      "outputs": [],
      "source": [
        "#Build a Simple Web UI\n",
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from transformers import pipeline\n",
        "\n",
        "st.title(\"LinkedIn Post Generator (Local LLM)\")\n",
        "theme = st.selectbox(\"Theme\", [\"New Job\", \"Promotion\", \"Hiring\", \"Career Advice\"])\n",
        "tone = st.selectbox(\"Tone\", [\"Confident\", \"Humble\", \"Inspirational\", \"Professional\"])\n",
        "persona = st.text_input(\"Your Role\", \"Software Engineer\")\n",
        "event = st.text_area(\"Event Description\", \"Started a new role at Google\")\n",
        "\n",
        "if st.button(\"Generate Post\"):\n",
        "    prompt = f\"\"\"### INSTRUCTION:\n",
        "Write a {tone.lower()} LinkedIn post on the theme \"{theme.lower()}\".\n",
        "Role: {persona}\n",
        "Event: {event}\n",
        "### RESPONSE:\n",
        "\"\"\"\n",
        "    response = pipe(prompt, max_new_tokens=200, do_sample=True)[0]['generated_text']\n",
        "    st.write(response)"
      ],
      "metadata": {
        "id": "DxD5KHt_HMpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run linkedin_generator_ui.py"
      ],
      "metadata": {
        "id": "ptO4WuM8HmX6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZTOhvGJWAg6XKpPB2hjCK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85ef379e0e0d4b9f8ec25dc0662d4228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97dfc0b239e7492c9e8c90153511b5eb",
              "IPY_MODEL_04501cc2625f43c888af4e4ce40e769d",
              "IPY_MODEL_0a89e9ccfcdf47109e08dc0ec242cd4a"
            ],
            "layout": "IPY_MODEL_56674944ffdd440091d747fe4c356a2d"
          }
        },
        "97dfc0b239e7492c9e8c90153511b5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5081fd0bddac4cc281942d21062b2cb0",
            "placeholder": "​",
            "style": "IPY_MODEL_71e762fe9c4f482381477093caf123c6",
            "value": "Map: 100%"
          }
        },
        "04501cc2625f43c888af4e4ce40e769d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9b74156137480782b5fcac99ed5b58",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67c5796d72aa4520851610dcfc8ec5a7",
            "value": 11
          }
        },
        "0a89e9ccfcdf47109e08dc0ec242cd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0978bbf58647fc95c43eccab69c085",
            "placeholder": "​",
            "style": "IPY_MODEL_562f683a35bc42178dda66fc7101cc10",
            "value": " 11/11 [00:00&lt;00:00, 89.06 examples/s]"
          }
        },
        "56674944ffdd440091d747fe4c356a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5081fd0bddac4cc281942d21062b2cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e762fe9c4f482381477093caf123c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de9b74156137480782b5fcac99ed5b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c5796d72aa4520851610dcfc8ec5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b0978bbf58647fc95c43eccab69c085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562f683a35bc42178dda66fc7101cc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8381042393434988a02f842b792a88df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c979df6e92145c38b7a12882b525b9e",
              "IPY_MODEL_723c1a03fb594acaae6686f9de62782d",
              "IPY_MODEL_520e4c6e881b4509b1f14538d0635071"
            ],
            "layout": "IPY_MODEL_eb2a586dfcee4a28a931d74960dc3b34"
          }
        },
        "7c979df6e92145c38b7a12882b525b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_819a6f1b76674e66a89806fd3b67ad42",
            "placeholder": "​",
            "style": "IPY_MODEL_cb283b10f6ba42ad96be1fc942fa9f3b",
            "value": "Map: 100%"
          }
        },
        "723c1a03fb594acaae6686f9de62782d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93600f43af54090a2f21c8919bcf8c2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c08de282526d448b8a9c3b84d7fffd73",
            "value": 2
          }
        },
        "520e4c6e881b4509b1f14538d0635071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab40ba5d09cd4f17990dcd63869f0b52",
            "placeholder": "​",
            "style": "IPY_MODEL_6e74b04d55d5406da1b7054b4ba12c5b",
            "value": " 2/2 [00:00&lt;00:00, 87.45 examples/s]"
          }
        },
        "eb2a586dfcee4a28a931d74960dc3b34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819a6f1b76674e66a89806fd3b67ad42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb283b10f6ba42ad96be1fc942fa9f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e93600f43af54090a2f21c8919bcf8c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c08de282526d448b8a9c3b84d7fffd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab40ba5d09cd4f17990dcd63869f0b52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e74b04d55d5406da1b7054b4ba12c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}